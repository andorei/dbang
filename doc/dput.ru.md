# dput. Загрузка данных из файла в БД

	версия 0.3

Чтобы загружать данные из файлов в вашу БД утилитой `dput`, один раз выполните тестовую загрузку в вашу БД с помощью конфиг-файла `dput-test-<source>.py`. При этом в БД будут созданы таблицы `ida` и `ida_lines`, куда по умолчанию будут загружаться данные.

Утилита `dput` загружает в БД данные из файлов форматов `xlsx`, `csv`, `json` и других текстовых форматов, согласно спецификации в конфиг-файле. Данные могут загружаться из одного файла или из серии файлов. Если входные файлы сжаты в архив `zip`,  то перед загрузкой они автоматически извлекаются из архива.

* [Тестовые файлы для загрузки](#тестовые-файлы-для-загрузки)
* [Основные возможности](#основные-возможности)
* [Процедура загрузки](#процедура-загрузки)
* [Загрузка данных в таблицу по умолчанию](#загрузка-данных-в-таблицу-по-умолчанию)
* [Избирательная загрузка строк и полей](#избирательная-загрузка-строк-и-полей)
* [Загрузка данных из файла JSON](#загрузка-данных-из-файла-json)
* [Загрузка данных в таблицу пользователя](#загрузка-данных-в-таблицу-пользователя)
* [Загрузка с распаковкой вложенного списка](#загрузка-с-распаковкой-вложенного-списка)
* [Загрузка в несколько таблиц пользователя](#загрузка-в-несколько-таблиц-пользователя)
* [Загрузка "вложенных таблиц" в таблицу по умолчанию](#загрузка--вложенных-таблиц--в-таблицу-по-умолчанию)
* [Загрузка специальных текстовых файлов](#загрузка-специальных-текстовых-файлов)
* [Три вида функций для `insert_data`](#три-вида-функций-для---insert_data--)
* [Аргументы командной строки](#аргументы-командной-строки)
* [Параметры конфиг-файла](#параметры-конфиг-файла)
* [Параметры спецификации](#параметры-спецификации)

## Тестовые файлы для загрузки

Файлы для тестовых загрузок расположены в директории `in`. Познакомьтесь с ними, чтобы понимать дальнейшие примеры.

Файлы с именем `test` и расширениями `xlsx`, `csv`, `json` и `dat` содержат справочник стран мира с четырьмя полями

* название страны,
* двухбуквенный код страны,
* трехбуквенный код страны,
* цифровой код страны.

Серии файлов с именами `test_000001`,  `test_000002`,  `test_000003` и расширениями `csv`, `xlsx` или `json` содержат тот же справочник стран мира, разбитый на три части.

Первые и последние пять строк из загрузочного файла `test.csv`:

```
Afghanistan;AF;AFG;004
Aland Islands;AX;ALA;248
Albania;AL;ALB;008
Algeria;DZ;DZA;012
American Samoa;AS;ASM;016
...
Wallis and Futuna Islands;WF;WLF;876
Western Sahara;EH;ESH;732
Yemen;YE;YEM;887
Zambia;ZM;ZMB;894
Zimbabwe;ZW;ZWE;716
```

Первые и последние пять строк файла `test.json`:

```
[
{"name": "Afghanistan", "alpha2": "AF", "alpha3": "AFG", "code": "004"},
{"alpha2": "AX", "alpha3": "ALA", "code": "248", "name": "Aland Islands"},
{"alpha3": "ALB", "code": "008", "name": "Albania", "alpha2": "AL"},
{"code": "012", "alpha2": "DZ",  "name": "Algeria", "alpha3": "DZA"},
{"name": "American Samoa", "code": "016", "alpha2": "AS", "alpha3": "ASM"},
...
{"name": "Wallis and Futuna Islands", "alpha2": "WF", "alpha3": "WLF", "code": "876"},
{"alpha2": "EH", "name": "Western Sahara", "alpha3": "ESH", "code": "732"},
{"alpha2": "YE", "alpha3": "YEM", "name": "Yemen", "code": "887"},
{"alpha2": "ZM", "alpha3": "ZMB", "code": "894", "name": "Zambia"},
{"code": "716", "name": "Zimbabwe", "alpha2": "ZW", "alpha3": "ZWE"}
]
```

Обратите внимание, что поля объектов JSON расположены в произвольном порядке.

## Основные возможности

Ниже пример спецификаций для SQLite , где данные загружаются из тестовых файлов в таблицу по умолчанию `ida_lines`.

Параметр `"file"` задает имя файла в директории `IN_DIR` и его формат:

```
# hello-dput.py

IN_DIR = os.path.join(os.path.dirname(__file__), '..', 'in')
SOURCE = sources['sqlite-source']

specs = {
    "hello-csv": {
        "file": "test.csv"
    },
    "hello-xlsx": {
        "file": "test.xlsx"
    },
    "hello-json": {
        "file": "test.json",
        "insert_data": lambda row: (row["code"], row["name"], row["alpha2"], row["alpha3"])
    },
    "hello-zip": {
        "file": "test_zip.zip"
    },
    "hello-series": {
        "file": "test_000???.csv",
        "insert_data": lambda row: (row[3], row[0], row[1])
    },
    ...
}
```

Параметр `"file"` спецификации `"hello-zip"` предписывает извлечь файл из архива `zip` и загрузить извлеченный файл. Архив `zip` должен содержать один файл с именем, равным имени `zip`-файла, и с расширением `csv`, `xlsx` или `json`.

Параметр `"file"` спецификации `"hello-series"` задает [glob-паттерн](https://docs.python.org/3/library/glob.html) для серии загружаемых файлов. Соответствующие файлы загружаются в алфавитном порядке.

Параметр `"insert_data"` спецификации `"hello-json"` определяет функцию для превращения объекта JSON в "строку" (row) данных – список (или кортеж) значений полей – для загрузки в таблицу БД. На вход функция получает словарь (dict), представляющий один объект JSON. 

Параметр `"insert_data"` спецификации `"hello-series"` демонстрирует возможность выбора и переупорядочивания полей `csv`-строк при загрузке. На вход функция получает список (или кортеж) со значениями полей строки `csv`-файла.

## Процедура загрузки

Загрузка данных в БД из файлов форматов `xlsx`, `csv` и других текстовых файлов выполняется построчно в порядке расположения строк в файле; из файла формата `json` – пообъектно в порядке расположения объектов в массиве JSON.

Далее по тексту термин "строка" означает единицу загрузки из файла, в том числе объект JSON.

Процедура загрузки с помощью `dput` опционально предусматривает

1. проверку, удовлетворяет ли каждая очередная строка условию загрузки; по результату проверки строка либо загружается в интерфейсную таблицу либо игнорируется;
2. формирование списка значений полей для загрузки в интерфейсную таблицу – в случае загрузки из файла `json` или в случае, когда не нужно загружать все поля строки;
3. проверку строк, загруженных в интерфейсную таблицу БД, на соответствие требованиям, включая согласованность с уже имеющимся в БД данным,
4. перенос строк из интерфейсной таблицы в целевые таблицы БД, для которых они предназначены.

Если загруженные в интерфейсную таблицу данные не проходят проверку на соответствие требованиям, то они не будут загружены в целевые таблицы БД, а пользователь получит сообщения об ошибках.

При этом простейшая спецификация для `dput` 
* содержит только имя файла для загрузки,
* не включает перечисленных проверок и переноса данных в целевые таблицы,
* позволяет загрузить все поля всех строк из файла в интерфейсную таблицу по умолчанию `ida_lines`.

Таблицы `ida` и `ida_lines` автоматически создаются в БД при выполнении спецификаций из тестового конфиг-файла и в дальнейшем используются с пользовательскими спецификациями по умолчанию. Вот их структура (в БД PostgreSQL):

```
create table if not exists ida (
    iload serial not null,
    idate timestamptz not null default now(),
    istat smallint not null default 0,
    imess varchar(4000),
    entity varchar(50) not null,
    ifile varchar(256) not null,
    iuser varchar(30),
    arg1 varchar(4000),
    arg2 varchar(4000),
    ...
    arg9 varchar(4000),
    primary key (iload)
);

create table if not exists ida_lines (
    iload int not null,
    iline int not null,
    ntable smallint not null default -1,
    nline int not null default -1,
    istat smallint not null default 0,
    ierrm varchar(4000),
    c1 varchar(4000),
    c2 varchar(4000),
    ...
    ...
    ...
    c100 varchar(4000),
    primary key (iload, iline, ntable, nline),
    foreign key (iload) references ida (iload) on delete cascade
);
```

В таблице `ida` фиксируются факты загрузки, в частности:

* идентификатор загрузки `iload`,
* время загрузки `idate`,
* статус загрузки `istat`,
* имя загруженного файла `ifile`,
* имя спецификации `entity`,
* итоговое сообщение о загрузке `imess` – если предусмотрено логикой обработки.

Таблица `ida_lines` содержит все строки из загружаемого файла, а также

* идентификатор загрузки `iload`,
* номер загруженной строки `iline`,
* номер "вложенной таблицы" `ntable`,
* номер загруженной строки "вложенной таблицы" `nline`,
* статус обработки строки `istat` и
* сообщение об ошибке `ierrm` – если ошибка обнаружится в ходе обработки.

Для загрузки строк не в таблицу `ida_lines`, а в другую, необходимо явно указать предложение SQL `insert` (или вызов хранимой процедуры) в спецификации. Подробности в разделе [Загрузка данных в таблицу пользователя](#загрузка-данных-в-таблицу-пользователя).

Данные, загруженные в интерфейсные таблицы `ida` и `ida_lines`, не сразу удаляются из этих таблиц. Параметр в конфиг-файле

```
PRESERVE_N_LOADS = 10
```

предписывает хранить в интерфейсных таблицах 10 последних загрузок по каждой спецификации из данного конфиг-файла. При выполнении 11-ой загрузки по той же спецификации самая старая из загрузок будет удалена. Если сделать `PRESERVE_N_LOADS` равным 0, то данные из таблиц будут удаляться сразу после выполнения спецификации.

Хранение загруженных данных в интерфейсных таблицах в течение некоторого времени полезно в случаях, когда нужно проверить, какие данные были загружены пользователями ранее и/или какие ошибки были найдены при их обработке.

В тестовых конфиг-файлах `dput-test-<source>.py` вы найдете комментарии к каждому из параметров спецификации. Познакомьтесь с ними, чтобы составить исчерпывающее представление обо всех параметрах и их назначении.

## Загрузка данных в таблицу по умолчанию

Разберем, как работает загрузка, на примере тестового загрузочного файла `test.csv` и спецификации из тестового конфиг-файла `dput-test-postgtres.py`:

```
specs = {
    ...
    "csv_ida_test": {
        "source": "postgres-source",
        "file": "test.csv",
        "validate_actions": [
            """
            update ida_lines set
                istat = 2,
                ierrm = trim(ierrm || ' Empty field.')
            where iload = %s
                and (c1 is null or c2 is null or c3 is null or c4 is null)
            """,
            """
            update ida_lines set
                istat = 2,
                ierrm = trim(ierrm || ' Not ALPHA2 code.')
            where iload = %s
                and length(c2) != 2
            """,
            """
            update ida_lines set
                istat = 2,
                ierrm = trim(ierrm || ' Not ALPHA3 code.')
            where iload = %s
                and length(c3) != 3
            """,
        ],
        "process_actions": [
            # just teardown
            "delete from ida where iload = %s"
        ]
    },
    ...
}
```

Согласно этой спецификации, утилита `dput`

1. загружает данные из файла `test.csv` в таблицу `ida_lines` в БД, заданной источником данных `"postgres-source"`, при этом в таблицу `ida` вставляется запись о факте загрузки;
2. выполняет SQL запросы, заданные параметром `"validate_actions"` (здесь могут быть и вызовы хранимых процедур), для проверки соответствия данных, загруженных в `ida_lines`, требованиям;
3. если проверка успешна, то
	* выполняет SQL запросы, заданные параметром `"process_actions"` (здесь могут быть и вызовы хранимых процедур) для переноса данных из `ida_lines` в целевые таблицы;
	иначе
	* пишет в лог-файл сообщения по результатам проверки.

При загрузке строк в таблицу `ida_lines` значения четырех полей из строк файла помещаются, соответственно, в столбцы `c1`, `с2`, `с3` и `с4`. Так как таблица `ida_lines` содержит 100 столбцов `c1`, .. `c100`, то число полей в загружаемом файле не может быть больше 100.

Статус строк `ida_lines.istat` после загрузки (шаг 1) равен 0 - "Ожидает обработки".

На шаге 2 предложения `update` из параметра `"validate_actions"` проверяют:

* что все 4 поля строки не пусты,
* что длина двухбуквенного кода страны равна 2,
* что длина трехбуквенного кода страны равна 3.

Строки, не прошедшие проверку, получают статус `ida_lines.istat = 2`, а в поле `ida_lines.ierrm` записывается сообщение о проблеме. Сообщения о найденных проблемах выводятся в лог-файл.

Если проверка на нашла проблем в данных, то выполняются предложения SQL из списка `"process_actions"`, назначение которых – перенести данные из `ida_lines` в целевые таблицы. В тестовой спецификации список `"process_actions"` содержит единственное предложение, удаляющее загруженные данные из таблиц `ida` и `ida_lines`. Тем самым, вместо переноса данных в целевые таблицы тестовые данные просто удаляются из БД.

Предложения в списках `"validate_actions"` и `"process_actions"` содержат одну связанную переменную (bind variable), в которую подставляется идентификатор текущей загрузки `iload`. Если для PostgreSQL место подстановки обозначается символами `%s`, то для других СУБД оно может обозначаться по-другому – это зависит от модуля, реализующего database API для СУБД. Чтобы узнать как, посмотрите тестовые конфиг-файлы `dput-test-sqlite.py`, `dput-test-oracle.py`, `dput-test-mysql.py`.

Если хотя бы одна строка `ida_lines` была помечена как проблемная, то утилита `"dput"` установит общий статус загрузки `ida.istat` равным 2 - "Ошибка". Если все строки были обработаны успешно, то `ida.istat` получит значение 1 - "Обработка выполнена".

## Избирательная загрузка строк и полей

Опциональный параметр спецификации `"skip_lines"` позволяет задать количество строк, которые нужно пропустить в начале загружаемого файла. Например, значение `1` позволяет пропустить первую (вероятно, заголовочную) строку при загрузке файлов `csv` или `xlsx`.

Опциональный параметр спецификации `"insert_data"` задает функцию, которая позволяет
* загружать только указанные вами поля,
* загружать только строки, соответствующие заданному вами условию.

Параметр `"insert_data"` может задавать лямбда-функцию или обычную функцию Python, определенную в конфиг-файле.

Рассмотрим избирательную загрузку строк и полей на примере спецификации `"selected_ida_test"` из тестового конфиг-файла:

```
"selected_ida_test": {
    "file": "test.csv",
    #
    # tuple of values to insert into ida_lines table
    #
    "insert_data": lambda row: (row[3], row[0]) if row[0][0] in 'AEIOU' else None
}
```

Функция, заданная параметром `"insert_data"` ,
* вызывается для каждой строки загружаемого файла,
* получает в качестве параметра список (list) или кортеж (tuple) всех полей строки,
* возвращает список (list) или кортеж (tuple) полей строки, которые должны быть загружены,
* или возвращает `None`, если данную строку не нужно загружать.

Лямбда-функция в приведенной спецификации возвращает кортеж `(<цифровой код страны>, <название страны>)` для строк, где название страны начинается с гласной буквы, и возвращает `None` в остальных случаях. Таким образом, в таблицу `ida_lines` загрузится только часть строк и полей из загрузочного файла.

## Загрузка данных из файла JSON

Параметр `"insert_data"` обязателен в спецификации для загрузки строк из json-файла, даже если это загрузка в таблицу `ida_lines`. Это связано с тем, что поля объектов JSON могут располагаться в произвольном порядке.

Пример спецификации для загрузки данных из файла `test.json` в таблицу `ida_lines`:

```
"json_ida_test": {
	"file": "test.json",
	#
	# tuple of values to insert into ida_lines table
	#
	"insert_data": lambda row: (row["code"], row["name"], row["alpha2"], row["alpha3"])
}
```

## Загрузка данных в таблицу пользователя

Вместо загрузки строк из файла в таблицу `ida_lines`, есть возможность загружать их в другую таблицу. Для этого необходимо установить параметры спецификации `"insert_actions"` и `"insert_data"`.

Пусть в БД уже имеется интерфейсная таблица для загрузки справочника стран:

```
create table if not exists test (
    code varchar(3) not null,
    name varchar(50) not null,
    alpha2 char(2),
    alpha3 char(3)
)
```

Тогда следующая спецификация позволяет загрузить в нее строки из файла `test.csv`:

```
"csv_test_test": {
	"file": "test.csv",
	"insert_actions": """
		insert into test (code, name, alpha2, alpha3)
		values (%s, %s, %s, %s)
	""",
	"insert_data": lambda row: (row[3], row[0], row[1], row[2])
}
```

Параметр `"insert_actions"` содержит предложение SQL `insert` для вставки строки в таблицу `test`. Так как порядок столбцов в предложении `insert` отличается от порядка полей в загружаемом файле (см. [Тестовые файлы для загрузки](#тестовые-файлы-для-загрузки)), то функция, заданная параметром `"insert_data"`, располагает поля в нужном порядке.

Если в предложении `insert` указать столбцы в том же порядке, в котором расположены поля в файле `csv`, то параметр `"insert_data"` можно опустить:

```
"csv_test_test": {
	"file": "test.csv",
	insert_statement": """
		insert into test (name, alpha2, alpha3, code)
		values (%s, %s, %s, %s)
	"""
}
```

Здесь важно, что каждое из четырех полей строки файла `csv` имеет соответствующий ему столбец в предложении `insert`. Тогда как при помощи параметра `"insert_data"` можно организовать вставку в таблицу избранных полей строки.

При загрузке данных в таблицу пользователя, как и при загрузке в интерфейсную таблицу по умолчанию, утилита `dput` регистрирует факт загрузки в таблице `ida`.

Если пользовательские команды для валидации и/или обработки загруженных данных (`"validate_actions"` и `"process_actions"`) изменят статус загрузки `ida.istat` на 2 - "Ошибка" и поместят в `ida.imess` сообщение об ошибке, то утилита `dput` выведет сообщение об ошибке в лог. В противном случае статус загрузки будет установлен равным 1 - "Обработка выполнена" и в лог будет выведено сообщение об успешной обработке данных.

## Загрузка с распаковкой вложенного списка

Каждая строка тестового файла `test_nested_00.csv` содержит два поля:
1. номер этажа торгового центра,
2. список магазинов на этаже.

Вот его содержание:

```
1;ABC,Bonus,Cosmos,Domus,Eidos
2;Focus,Iris
3;Lotus
4;
```

Второе поле, по сути, представляет собой вложенную структуру данных. Этот список необходимо развернуть, или распаковать, так, чтобы загрузить в интерфейсную таблицу БД строки (rows) с полями, не содержащими вложенных структур. Для этого в спецификации `"nested_00_ida"` параметр `"insert_data"` задает функцию, которая для одного кортежа на входе, представляющего строку из файла,  возвращает список (!) кортежей, представляющих строки для загрузки в таблицу БД:

```
"nested_00_ida": {
    "file": "test_nested_00.csv",
    "insert_data": \
        lambda row: [
            (row[0], n) for n in row[1].split(',')
        ] if row[1] else []
}
```

Результат загрузки данных спецификацией `nested_00_ida` в таблицу `ida_lines`:

```
|iload|iline|ntable|nline|c1 |c2    |
|-----|-----|------|-----|---|------|
|42   |1    |0     |1    |1  |ABC   |
|42   |1    |0     |2    |1  |Bonus |
|42   |1    |0     |3    |1  |Cosmos|
|42   |1    |0     |4    |1  |Domus |
|42   |1    |0     |5    |1  |Eidos |
|42   |2    |0     |1    |2  |Focus |
|42   |2    |0     |2    |2  |Iris  |
|42   |3    |0     |1    |3  |Lotus |
```

Обратите внимание, что
* столбец `iline` содержит номера загруженных из файла строк, 
* столбец `ntable` – номера распакованных вложенных структур ("вложенных таблиц"),
* столбец `nline` – номера элементов распакованных вложенных структур (строк "вложенной таблицы").

## Загрузка в несколько таблиц пользователя

Файлы формата JSON позволяют представлять вложенные структуры данных, которые отображаются на более чем одну таблицу реляционной схемы данных.

Например, тестовый файл `test_nested_01.json` содержит 7 объектов JSON c 2 полями
* `"region"` – название мирового региона или континента,
* `"countries"` – массив объектов JSON, описывающих страны данного региона.

Вот первые строки этого файла:

```
{
    "region": "Nowhere",
    "countries": []
},
{
    "region": "Antarctica",
    "countries": [
		{"name": "Antarctica", "alpha2": "AQ", "alpha3": "ATA", "code": "010"},
		{"name": "Bouvet Island", "alpha2": "BV", "alpha3": "BVT", "code": "074"}
    ]
},
{
    "region": "Africa",
    "countries": [
		{"name": "Comoros", "alpha2": "KM", "alpha3": "COM", "code": "174"},
		{"name": "Djibouti", "alpha2": "DJ", "alpha3": "DJI", "code": "262"},
		...
```

Представленные в файле данные естественным образом отображаются в две таблицы:
1. (родительская) таблица регионов и
2. (дочерняя) таблица стран, ссылающаяся на таблицу регионов.

Для загрузки данных из файла в несколько таблиц пользователя в спецификации необходимо указать предложение `insert` и значения полей для каждой таблицы:

```
"nested_01_test": {
    "file": "test_nested_01.json",
    "insert_actions": [
        "insert into test_region (region, contains) values (?, ?)",
        "insert into test_countries (region, code, name) values (?, ?, ?)"
    ],
    "insert_data": [
        lambda row: (row['region'], len(row['countries'])),
        lambda row: [
                (row['region'], n['code'], n['name']) \
                for n in row['countries']
            ] if row['countries'] else []
    ]
}
```

В данном случае параметры спецификации `"insert_actions"` и `"insert_data"` – это список строк (str) и список функций, соответственно. Каждому предложению `insert` в списке `"insert_actions"` соответствует функция в списке `"insert_data"`.

Обратите внимание, что первая функция возвращает кортеж из двух элементов, представляющий одну строку родительской таблицы регионов. А вторая функция возвращает список кортежей, представляющий множество строк дочерней таблицы стран.

Загрузка данных в несколько таблиц может быть полезна не только для файлов формата JSON. Файлы форматов `csv` и `xlsx` также могут содержать в одной строке данные, которые отображаются на более чем одну таблицу. В этом случае говорят, что данные в файлах денормализованы – с точки зрения реляционной схемы.

## Загрузка "вложенных таблиц" в таблицу по умолчанию

Для загрузки вложенных структур в интерфейсную таблицу по умолчанию `ida_lines` необходимо в параметре спецификации `"insert_data"` задать список функций, по одной для строк каждой "таблицы": родительской и вложенных.

Загрузим файл `test_nested_01.json`, описанный выше, в таблицу `ida_lines`:

```
"nested_01_ida": {
    "file": "test_nested_01.json",
    "insert_data": [
        lambda row: (row['region'], len(row['countries'])),
        lambda row: [
            (n['code'], n['name'], n['alpha2'], n['alpha3']) \
                for n in row['countries']
            ] if row['countries'] else []
    ]
}
```

Первая функция в списке `insert_data` формирует строку "родительской таблицы", вторая функция – множество строк для "вложенной таблицы" №1, третья (если бы она была определена) – множество строк для "вложенной таблицы" №2, и так далее.

Первые 10 строк, загруженные спецификацией `nested_01_ida` в таблицу `ida_lines`:

```
|iload|iline|ntable|nline|c1        |c2               |c3 |c4 |
|-----|-----|------|-----|----------|-----------------|---|---|
|41   |1    |-1    |-1   |Nowhere   |0                |   |   |
|41   |2    |-1    |-1   |Antarctica|2                |   |   |
|41   |2    |1     |1    |010       |Antarctica       |AQ |ATA|
|41   |2    |1     |2    |074       |Bouvet Island    |BV |BVT|
|41   |3    |-1    |-1   |Africa    |59               |   |   |
|41   |3    |1     |1    |174       |Comoros          |KM |COM|
|41   |3    |1     |2    |262       |Djibouti         |DJ |DJI|
|41   |3    |1     |3    |226       |Equatorial Guinea|GQ |GNQ|
|41   |3    |1     |4    |232       |Eritrea          |ER |ERI|
|41   |3    |1     |5    |324       |Guinea           |GN |GIN|
```

Обратите внимание, что
* столбец `iline` содержит номера загруженных из файла строк,
* столбец `ntable` – номера распакованных вложенных структур ("вложенных таблиц") или `-1` для "родительской таблицы",
* столбец `nline` – номера элементов распакованных вложенных структур (строк "вложенных таблиц") или `-1` для "родительской таблицы".

## Загрузка специальных текстовых файлов

Иногда возникает необходимость загружать в БД данные из текстовых файлов специальных форматов, например,
* файл, первые строки которого описывают данные в последующих строках, или
* файл со строками с полями фиксированной длины (без разделителей).

Параметр спецификации `"pass_lines": True` предписывает утилите `dput` передавать на вход функции, заданной параметром `"insert_data"`, строки текстового файла как есть, без предварительного разбиения на поля.

В этом случае функция, заданная параметром `"insert_data"`, выполняет разбор полученной текстовой строки и возвращает список (list) или кортеж (tuple) значений полей для загрузки в БД.

Тестовый файл `test_special.dat` содержит знакомый нам справочник стран мира в строках следующего формата:
1. двухбуквенный код страны – позиции с 1 по 2,
2. трехбуквенный код страны – позиции с 3 по 5,
3. цифровой код страны – позиции с 6 по 8,
4. название страны – позиции с 9 до конца строки.

Вот пять первых и последних строк этого файла:

```
AFAFG004Afghanistan
AXALA248Aland Islands
ALALB008Albania
DZDZA012Algeria
ASASM016American Samoa
...
WFWLF876Wallis and Futuna Islands
EHESH732Western Sahara
YEYEM887Yemen
ZMZMB894Zambia
ZWZWE716Zimbabwe
```

Спецификация `"special_03_ida"` загружает в таблицу `ida_lines` четыре отдельных поля, извлекая их значения из строк файла с помощью функции `special_03_data` (это могла бы быть и лямбда-функция):

```
...

def special_03_ida(line):
    """
    line    - line content, e.g. AFAFG004Afghanistan
    """
    return (line[0:2], line[2:5], line[5:8], line[8:].strip())


specs = {
	...
    "special_03_ida": {
        "file": "test_special.dat",
        "pass_lines": True,
        "insert_data": special_03_ida
    },
	...
}
```

## Три вида функций для `"insert_data"`

Функции, задаваемые параметром спецификации `"insert_data"`, могут быть трех видов:

| Вид функции                 | Описание                           |
| --------------------------- | ---------------------------------- |
| `<func>(row)`               | `row` - список значений полей или строка текстового файла как есть, если `"pass_lines": True` |
| `<func>(line_no, row)`      | `line_no` - номер строки файла, `row` - список значений полей или строка текстового файла как есть, если `"pass_lines": True` |
| `<func>(iload, iline, row)` | `iload` - идентификатор загрузки, `iline` - номер загруженной строки, `row` - список значений полей или строка текстового файла как есть, если `"pass_lines": True` |

При загрузке данных из единственного файла номер строки файла `line_no` и номер загруженной строки `iline` совпадают.

В случае загрузки данных из серии файлов, номер строки файла `line_no` возобновляет отсчет  с `1` для каждого файла в серии, а номер загруженной строки `iline` непрерывно возрастает на протяжении загрузки всех файлов серии.

Функции вида  `<func>(line_no, row)` позволяют обрабатывать специальные текстовые файлы, которые в первых строках содержат метаданные, необходимые для правильной обработки последующих строк. См. пример загрузки файла `test_special.csv` с помощью спецификации `"special_01_ida"` в тестовых конфиг-файлах.

Функции вида `<func>(iload, iline, row)` позволяют загружать данные в несколько логически связанных таблиц (например, в родительскую и дочерние), генерируя уникальный ключ родительской таблицы и внешний ключ дочерних из значений `iload` и `iline`. См. пример загрузки файла `test_nested_01.csv` с помощью спецификации `"nested_01_keygen"` в тестовых конфиг-файлах.

## Аргументы командной строки

```
$ ./dput.py -h
usage: dput.py [-h] [-a ARG] [-d] [-f] [-t] [-u USER] [-v] cfg_file spec [in_file]

Load data from file into DB, as specified in cfg-file spec.

positional arguments:
  cfg_file              cfg-file name
  spec                  spec name
  in_file               input file name

options:
  -h, --help            show this help message and exit
  -a ARG, --arg ARG     pass one or more arguments to SQL query
  -d, --delete          delete loaded data file(s)
  -f, --force           load data file(s) unconditionally
  -t, --trace           enable tracing
  -u USER, --user USER  set data loader username
  -v, --version         show program's version number and exit

Thanks for using dput.py!
```

Обязательны только имя конфиг-файла `cfg_file` и имя спецификации `spec`.

Для выполнения всех спецификаций из конфиг-файла вместо имени спецификации укажите ключевое слово `all`.

Если задано имя входного файла `in_file`, то данные загружаются из указанного файла вместо файла, заданного параметром `"file"` спецификации. При этом формат входного файла определяется по его расширению – так же, как и в случае задания файла параметром `"file"`.

Ключ `-a` или `--arg` позволяет передать от одного до 9 аргументов в строку таблицы `ida`, которая описывает факт данной загрузки. Далее загруженные аргументы могут использоваться в предложениях SQL или хранимых процедурах, заданных параметрами спецификации `"validate_actions"` и `"process_actions"`. Чтобы сделать возможным загрузку аргументов в таблицу `ida`, нужно в параметре спецификации `"args"` определить массив значений аргументов по умолчанию.

Ключ `-d` или `--delete` предписывает утилите `dput` удалить входной файл после того, как он успешно загружен. Файл не будет удален, если в ходе загрузки или обработки возникнет ошибка.

Ключ `-f` или `--force` предписывает утилите `dput` загрузить данные из файла даже в том случае, если загрузка из этого файла уже была выполнена ранее. Утилита `dput` запоминает имена и время обновления загруженных файлов в служебном файле `~/.gput-<cfg-file>.json` и по умолчанию, то есть, без ключа `-f`, загружает только файлы, которые не были загружены ранее.

Ключ `-u` или `--user` позволяет передать имя пользователя, которое будет загружено в строку таблицы `ida`.

Ключ `-t` или `--trace` предписывает утилите `dput` создать трейс-файл в директории `~/.dbang`. Это файл нулевой длины с именем `dput#<spec>#<user>#<timestamp>#<status>`, где `<status>` принимает значения 0 - выполняется, 1 - выполнение завершено успешно, 2 - выполнение завершено с ошибкой.

## Параметры конфиг-файла

Параметры конфиг-файла суть переменные с именами в верхнем регистре, задающие контекст для выполнения спецификаций из данного конфиг-файла. См. также [Структура конфиг-файлов](conf.ru.md).

Параметры конфиг-файла для `dput` приведены ниже.

| Параметр            | Значение по умолчанию                    | Описание                                                     |
| ------------------- | ---------------------------------------- | ------------------------------------------------------------ |
| `DEBUGGING`         | `False`                                  | Режим отладки?                                               |
| `LOGGING`           | = DEBUGGING                              | Писать в лог-файл?                                           |
| `LOG_DIR`           | `./`                                     | Директория для лог-файлов.                                   |
| `IN_DIR`            | `./`                                     | Директория для загружаемых файлов.                           |
| `ENCODING`*         | `locale.getpreferredencoding()`          | Кодировка загружаемых файлов.                                |
| `CSV_DIALECT`*      | `excel`                                  | Диалект `csv`.                                               |
| `CSV_DELIMITER`*    | `csv.get_dialect(CSV_DIALECT).delimiter` | Разделитель полей `csv`.                                     |
| `PRESERVE_N_LOADS`  | `10`                                     | Количество сохраняемых загрузок для каждой спецификации.     |
| `PRESERVE_N_TRACES` | `10`                                     | Количество сохраняемых трейс-файлов для каждой спецификации. |
| `SOURCE`*           |                                          | Имя источника данных, определенного в файле `sources.py`.    |
\* параметр конфиг-файла, помеченный звездочкой, на уровне спецификации может быть переопределен соответствующим параметром спецификации.

## Параметры спецификации

Спецификации находятся в конфиг-файле в словаре (dict) `specs` и содержат  **параметры спецификации**. См. также [Структура конфиг-файлов](conf.ru.md).

Параметры спецификации для `dput` приведены ниже. Если специально не оговорено, то параметр спецификации является необязательным и может быть опущен.

| Параметр спецификации | Описание                                                                                                                                                                                                             |
| --------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `"tags"`              | Список (list) тегов для выбора данной спецификации в командной строке.                                                                                                                                             |
| `"source"`            | Имя (str) источника данных (далее БД), определенного в файле `sources.py`. Если не задан, то используется параметр конфиг-файла `SOURCE`.                                                                          |
| `"doc"`               | Краткое описание/комментарий к спецификации.                                                                                                                                                                         |
| `"setup"`             | Список (list) предложений SQL для БД, выполняемых в начале выполнения спецификации.                                                                                                                                |
| `"upset"`             | Список (list) предложений SQL для БД, выполняемых при завершении спецификации.                                                                                                                                     |
| `"force"`             | Загружать данные из файла безусловно.                                                                                                                                                                                |
| **`"file"`**          | **ОБЯЗАТЕЛЬНОЕ** имя файла, из которого загружаются данные. Расширение файла задает формат данных. Имя файла может быть  [glob-паттерном](https://docs.python.org/3/library/glob.html) для серии загружаемых файлов. |
| **`"args"`**          | Список (list) аргументов по умолчанию для загрузки в столбцы `arg1, ..., arg9` таблицы `ida`.                                                                                                                      |
| `"encoding"`          | Кодировка загружаемого файла. По умолчанию определяется параметром конфиг-файла `ENCODING`.                                                                                                                          |
| `"csv_dialect"`       | Диалект формата `csv`. По умолчанию определяется параметром конфиг-файла `CSV_DIALECT`.                                                                                                                              |
| `"csv_delimiter"`     | Разделитель полей формата `csv`. По умолчанию определяется параметром конфиг-файла `CSV_DELIMITER`.                                                                                                                  |
| `"skip_lines"`        | Количество (`int`) строк, которые необходимо пропустить в начале загружаемого файла.                                                                                                                                 |
| **`"insert_data"`**   | Функция или список (list) функций для преобразования строки данных из загружаемого файла в данные для таблицы БД.                                                                                                  |
| `"pass_lines"`        | Передавать строки текстового файла как есть в функции, заданные параметром `"insert_data"`?                                                                                                                          |
| `"insert_actions"`    | Список (list) предложений SQL или вызовов хранимых процедур для вставки строки данных в интерфейсную таблицу БД.                                                                                                   |
| `"validate_actions"`  | Список (list) предложений SQL или вызовов хранимых процедур для проверки корректности данных, загруженных в интерфейсную таблицу БД.                                                                               |
| `"process_actions"`   | Список (list) предложений SQL или вызовов хранимых процедур для переноса данных из интерфейсной таблицы в целевые таблицы БД.                                                                                      |