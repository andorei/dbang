# dput. Загрузка данных из файла в БД

Чтобы загружать данные из ваших файлов в вашу БД, один раз выполните тестовую загрузку в вашу БД с помощью конфиг-файла `dput-test-<source>.py`. При этом в БД будут созданы таблицы `ida` и `ida_lines`, куда по умолчанию будут загружаться данные.


* [Загрузка данных в таблицы по умолчанию](#загрузка-данных-в-таблицы-по-умолчанию)
* [Загрузка данных в таблицу пользователя](#загрузка-данных-в-таблицу-пользователя)
* [Загрузка данных из файла JSON](#загрузка-данных-из-файла-json)


## Загрузка данных в таблицы по умолчанию

Загрузка данных из файла в БД обычно предполагает:

* проверку данных из файла на соответствие требованиям,
* размещение данных в целевых таблицах БД, для которых они предназначены.

Если данные в файле не соответствуют предъявляемым к ним требованиям, то они не будут загружены в целевые таблицы БД, а пользователь получит сообщения об ошибках.

Утилита `dput`

* загружает данные из файла `csv`, `xlsx` или `json` в таблицы `ida` и `ida_lines` (если в спецификации не задана другая таблица) в БД, указанной в спецификации;
* выполняет SQL запросы из спецификации для проверки соответствия данных, загруженных в `ida_lines` (или другую таблицу), требованиям;
* если проверка успешна, выполняет SQL запросы из спецификации для переноса данных из `ida_lines` (или другой таблицы) в целевые таблицы;
* если проверка не успешна, пишет в лог-файл сообщения об ошибках, сформированные в ходе проверки.

Таблицы `ida` и `ida_lines` автоматически создаются в БД при выполнении спецификаций из тестового конфиг-файла и в дальнейшем по умолчанию используются с пользовательскими спецификациями. Вот их структура (в БД PostgreSQL):

```
create table if not exists ida (
    iload serial4 not null,
    idate timestamptz not null default now(),
    istat int2 not null default 0,
    imess varchar(4000),
    entity varchar(50) not null,
    ifile varchar(256) not null,
    iuser varchar(30),
    primary key (iload)
);

create table if not exists ida_lines (
    iload int not null,
    iline int not null,
    istat smallint not null default 0,
    ierrm varchar(4000),
    c1 varchar(4000),
    c2 varchar(4000),
    ...
    ...
    ...
    c100 varchar(4000),
    primary key (iload, iline),
    foreign key (iload) references ida(iload) on delete cascade
);
```

В таблице `ida` фиксируются факты загрузки, в частности:

* идентификатор загрузки `iload`,
* время загрузки `idate`,
* статус загрузки `istat`,
* имя загруженного файла `ifile`,
* имя спецификации `entity`.

Таблица `ida_lines` содержит все строки из загружаемого файла, а также

* идентификатор загрузки `iload`,
* номер строки `iline`,
* статус обработки строки `istat` и
* сообщение об ошибке `ierrm` – если ошибка обнаружится в ходе обработки.

Разберем, как работает загрузка, на примере тестового загрузочного файла `test.csv` и спецификации из тестового конфиг-файла `dput-test-postgtres.py`.

Загрузочный файл `test.csv` содержит справочник стран мира с четырьмя полями

* название страны,
* двухбуквенный код страны,
* трехбуквенный код страны,
* цифровой код страны.

Первые и последние пять строк из загрузочного файла:

```
Afghanistan;AF;AFG;004
Aland Islands;AX;ALA;248
Albania;AL;ALB;008
Algeria;DZ;DZA;012
American Samoa;AS;ASM;016
...
Wallis and Futuna Islands;WF;WLF;876
Western Sahara;EH;ESH;732
Yemen;YE;YEM;887
Zambia;ZM;ZMB;894
Zimbabwe;ZW;ZWE;716
```

При загрузке строк в таблицу `ida_lines` значения полей будут помещены, соответственно, в столбцы таблицы `c1`, `с2`, `с3` и `с4`. (Так как таблица `ida_lines` содержит 100 столбцов `c1`, .. `c100`, то число полей в загружаемм файле не может быть больше 100.)

Статус строк `istat` сразу после загрузки равен 0 - "Ожидает обработки".

Тестовая спецификация для загрузки справочника стран мира в БД PostgreSQL:

```
specs = {
    ...
    "csv_ida_test": {
        #
        # database to load data into from csv file
        #
        "source": "postgres-source",
        #
        # file to load; should be specified here or/and on command line
        #
        "file": "test.csv",
        #
        # the following parameters default to the global ones
        #
        #"encoding": ENCODING,
        #"csv_dialect": CSV_DIALECT,
        #"csv_delimiter": CSV_DELIMITER,
        #"csv_quotechar": CSV_QUOTECHAR,
        #
        # how many last loads preserved in ida tables
        #
        #"preserve_n_loads": 10,
        #
        # optionally validate loaded data
        #
        "validate_statements": [
            """
            update ida_lines set
                istat = 2,
                ierrm = trim(ierrm || ' Empty field.')
            where iload = %s
                and (c1 is null or c2 is null or c3 is null or c4 is null)
            """,
            """
            update ida_lines set
                istat = 2,
                ierrm = trim(ierrm || ' Not ALPHA2 code.')
            where iload = %s
                and length(c2) != 2
            """,
            """
            update ida_lines set
                istat = 2,
                ierrm = trim(ierrm || ' Not ALPHA3 code.')
            where iload = %s
                and length(c3) != 3
            """,
        ],
        #
        # optionally process validated data
        #
        "process_statements": [
            # just teardown
            "delete from ida where iload = %s"
        ]
    },
    ...
}
```

Список `"validate_statements"` содержит предложения SQL для проверки выполнения требований к загружаемым данным. Эти предложения `dput` выполняет после загрузки строк в таблицу `ida_lines`.

Три предложения `update` в тестовой спецификации проверяют, соответственно:

* что все 4 поля строки не пусты,
* что длина двухбуквенного кода страны равна 2,
* что длина трехбуквенного кода страны равна 3.

В случае невыполнения требований, строка в `ida_lines` помечается как ошибочная (`istat = 2`), а в поле `ierrm` записывается сообщение об ошибке. В этом случае после выполнения `"validate_statements"` загрузка прекращается и в лог-файл выводятся номера проблемных строк и сообщения об ошибках.

Если предложения `"validate_statements"` не нашли ошибок, то далее выполняются предложения SQL из списка `"process_statements"`, назначение которых – перенести данные из `ida_lines` в целевые таблицы БД. Если в ходе выполнения `"process_statements"` некоторые строки `ida_lines` будут помечены как ошибочные, то сообщения об ошибках будут выведены в лог-файл.

В рассматриваемой тестовой спецификации список `"process_statements"` содержит единственное предложение, удаляющее загруженные данные из таблиц `ida` и `ida_lines`. Тем самым, вместо переноса данных в целевые таблицы тестовые данные просто удаляются из БД.

Предложения в списках `"validate_statements"` и `"process_statements"` содержат одну связанную переменную (bind variable), в которую подставляется идентификатор текущей загрузки `iload`. Если для PostgreSQL место подстановки обозначается символами `%s`, то для других СУБД оно может обозначаться по-другому – это зависит от модуля, реализующего database API для СУБД. Чтобы узнать как, посмотрите тестовые конфиг-файлы `dput-test-sqlite.py`, `dput-test-oracle.py`, `dput-test-mysql.py`.

Если валидация и обработка не пометили ни одну строку в таблице `ida_lines` как ошибочную, утилита `"dput"` установит статус загрузки `ida.istat` равным 1 - "Обработка выполнена".

Данные, загружаемые в БД через интерфейсные таблицы `ida` и `ida_lines`, по умолчанию не сразу удаляются из этих таблиц. Параметр в конфиг-файле

```
PRESERVE_N_LOADS = 10
```

предписывает хранить в интерфейсных таблицах 10 последних загрузок по каждой спецификации из данного конфиг-файла. При выполнении 11-ой загрузки по той же спецификации самая старая из загрузок будет удалена. Если сделать `PRESERVE_N_LOADS` равным 0, то данные из таблиц будут удаляться сразу после выполнения предложениий `"process_statements"`.

Хранение загруженных данных в интерфейсных таблицах в течение некоторого времени полезно в случаях, когда нужно проверить, какие данные были загружены пользователями ранее и/или какие ошибки были найдены при их обработке.

В тестовых конфиг-файлах `dput-test-<source>.py` вы найдете комментарии к каждому из параметров спецификации. Познакомьтесь с ними, чтобы составить исчерпывающее представление обо всех параметрах и их назначении.


## Загрузка данных в таблицу пользователя

Вместо загрузки строк из файла в таблицу `ida_lines`, есть возможность загружать их в другую таблицу. Например, в вашей БД может быть интерфейсная таблица, в которую загружаются данные для последующей обработки хранимой процедурой. Для загрузки в нее данных из файла улититой `dput` необходимо установить параметры спецификации `"insert_statement"` и `"insert_values"`.

Например, пусть в БД имеется интерфейсная таблица для загрузки справочника стран:

```
create table if not exists test (
    code varchar(3) not null,
    name varchar(50) not null,
    alpha2 char(2),
    alpha3 char(3)
)
```

Тогда следующая спецификация позволяет загрузить в нее строки из файла `test.csv`:

```
specs = {
    "csv_test_test": {
        "source": "postgres-source",
        "file": "test.csv",
        #
        # statement to insert data into user defined table
        #
        insert_statement": """
            insert into test (
                code, name, alpha2, alpha3)
            values (
                %s, %s, %s, %s)
        """,
        #
        # tuple of values to insert with the insert statement
        #
        "insert_values": lambda row: (row[3], row[0], row[1], row[2])
    },
    ...
}
```

Параметр `"insert_statement"` содержит предложение SQL `insert` для вставки строки в таблицу `test`. Так как порядок столбцов в предложении `insert` отличается от порядка полей в загружаемом csv-файле (см. выше), то параметр `"insert_values"` содержит лямбда-функцию Python, которая размещает поля в нужном для предложения `insert` порядке: числовой код, название страны, двухбуквенный код, трехбуквенный код.

Если в предложении `insert` указать столбцы в том же порядке, что и поля csv-файла, то параметр `"insert_values"` можно опустить:

```
specs = {
    "csv_test_test": {
        "source": "postgres-source",
        "file": "test.csv",
        insert_statement": """
            insert into test (
                name, alpha2, alpha3, code)
            values (
                %s, %s, %s, %s)
        """
    },
    ...
}
```

В последнем случае важно также то, что каждое из 4 полей строки csv-файла имеет соответствущий ему столбец таблицы `test`. Тогда как при помощи параметра `"insert_values"` можно организовать вставку в таблицу не всех, а только некоторых полей строки.

При загрузке данных в таблицу, заданную пользователем с помощью `"insert_statement"`, утилита `dput`, тем не менее, регистрирует факт загрузки в таблице `ida` со статусом 0 - "Ожидает обработки".

Если пользовательские команды для валидации и/или обработки загруженных данных (`"validate_statements"` и `"process_statements"`) изменят статус загрузки `ida.istat` на 2 - "Ошибка" и поместят в `ida.imess` сообщение об ошибке, то утилита `"dput"` выведет сообщение об ошибке в лог. В противном случае статус загрузки будет установлен равным 1 - "Обработка выполнена" и в лог будет выведено сообщение об успешной обработке данных.


## Загрузка данных из файла JSON

Параметр `"insert_values"` обязателен в спецификации для загрузки строк из json-файла, даже если это загрузка в таблицу `ida_lines` по умолчанию. Это связано с тем, что поля объектов JSON ("строк" в json-файле) могут располагаться в произвольном порядке. Ниже приведены пять первых и пять последних строк файла `test.json`, который можно найти в каталоге `in`:

```
[
{"name": "Afghanistan", "alpha2": "AF", "alpha3": "AFG", "code": "004"},
{"alpha2": "AX", "alpha3": "ALA", "code": "248", "name": "Aland Islands"},
{"alpha3": "ALB", "code": "008", "name": "Albania", "alpha2": "AL"},
{"code": "012", "alpha2": "DZ",  "name": "Algeria", "alpha3": "DZA"},
{"name": "American Samoa", "code": "016", "alpha2": "AS", "alpha3": "ASM"},
...
{"name": "Wallis and Futuna Islands", "alpha2": "WF", "alpha3": "WLF", "code": "876"},
{"alpha2": "EH", "name": "Western Sahara", "alpha3": "ESH", "code": "732"},
{"alpha2": "YE", "alpha3": "YEM", "name": "Yemen", "code": "887"},
{"alpha2": "ZM", "alpha3": "ZMB", "code": "894", "name": "Zambia"},
{"code": "716", "name": "Zimbabwe", "alpha2": "ZW", "alpha3": "ZWE"}
]
```

Пример спецификации для загрузки данных из файла `test.json` в таблицу `ida_lines`:

```
specs = {
    "json_ida_test": {
        "source": "postgres-source",
        "file": "test.json",
        #
        # tuple of values to insert into ida_lines table
        #
        "insert_values": lambda row: (row["code"], row["name"], row.get("alpha2"), row.get("alpha3"))
    },
    ...
```
